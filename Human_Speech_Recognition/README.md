**Emotion Recognition through Speech**

The goal to this project was to build and therefore improve two CNN models that recognizes 7 emotions (happiness, anger, sadness, calmness, fear, surprise, disgust, and neutrality) using human speech in English. In order to use my database, I had to transform the audio files into images, therefore one is based on spectograms and the other on MFCCs (Mel Frequency Cepstral Coefficients)

*Technologies* : Python, Pandas, NumPy, Matplotlib, Sci-kit Learn, Keras, Tensorflow, Librosa

[MFCCs](https://github.com/vaggos3625/Portfolio/blob/main/Human_Speech_Recognition/Librosa_model.ipynb)


[Spectrogram](https://github.com/vaggos3625/Portfolio/blob/main/Human_Speech_Recognition/Librosa_model.ipynb)
